== 8章: 沢山の化合物を一度にみたい
:imagesdir: images

image:jupyter.png[link="https://github.com/Mishima-syk/py4chemoinformatics/blob/master/notebooks/ch08_visualization.ipynb"]

沢山のデータがどのように分布しているのかを見るには適当な空間にマッピングするのが一般的です。特にケモインフォマティクスではケミカルスペースという言葉が使われます。

=== Chemical Spaceとは

ケミカルスペースとは化合物を何らかの尺度でn次元の空間に配置したものを指します。一般に、2次元または3次元が使われることが多いです（人間の理解のため）。尺度つまり類似性に関しては色々な手法が提案されていますが、うまく化合物の特徴を表すような距離が定義されるように決められることが多いです。

今回は睡眠薬のターゲットとして知られているOrexin Receptorのアンタゴニストについて、どの製薬企業がどういった化合物を開発しているのかを視覚化してみます。データのダウンロード方法は4章を参照してください。今回は表の10個の論文のデータを利用しました。

今回知りたいことは主に以下の２つです。

- 似たような化合物を開発していた会社はあったのか？
- Merckは似たような骨格ばかり最適化していたのか、それとも複数の骨格を最適化したのか？

.Orexin Receptor Antagonist
|===
|Doc ID|Journal|Pharma
|CHEMBL3098111|link:https://www.sciencedirect.com/science/article/pii/S0960894X13012511?via%3Dihub[Bioorg. Med. Chem. Lett. (2013) 23:6620-6624]|Merck
|CHEMBL3867477|link:https://www.sciencedirect.com/science/article/pii/S0960894X16310472?via%3Dihub[Bioorg Med Chem Lett (2016) 26:5809-5814]|Merck
|CHEMBL2380240|link:https://www.sciencedirect.com/science/article/pii/S0960894X13002801?via%3Dihub[Bioorg. Med. Chem. Lett. (2013) 23:2653-2658]|Rottapharm
|CHEMBL3352684|link:https://www.sciencedirect.com/science/article/pii/S0960894X14008853?via%3Dihub[Bioorg. Med. Chem. Lett. (2014) 24:4884-4890]|Merck
|CHEMBL3769367|link:https://pubs.acs.org/doi/10.1021/acs.jmedchem.5b00832[J. Med. Chem. (2016) 59:504-530]|Merck
|CHEMBL3526050|link:http://dmd.aspetjournals.org/content/41/5/1046[Drug Metab. Dispos. (2013) 41:1046-1059]|Actelion
|CHEMBL3112474|link:https://www.sciencedirect.com/science/article/pii/S0960894X13014765?via%3Dihub[Bioorg. Med. Chem. Lett. (2014) 24:1201-1208]|Actelion
|CHEMBL3739366|link:https://pubs.rsc.org/en/Content/ArticleLanding/2015/MD/C5MD00027K#!divAbstract[MedChemComm (2015) 6:947-955]|Heptares
|CHEMBL3739395|link:https://pubs.rsc.org/en/Content/ArticleLanding/2015/MD/C5MD00074B#!divAbstract[MedChemComm (2015) 6:1054-1064]|Actelion
|CHEMBL3351489|link:https://www.sciencedirect.com/science/article/pii/S0968089614006300?via%3Dihub[Bioorg. Med. Chem. (2014) 22:6071-6088]|Eisai
|===


=== ユークリッド距離を用いたマッピング

描画ライブラリにはggplotを使います。主成分分析(PCA)を利用して、化合物が似ているものは近くになるように分布させて可視化します。まずは必要なライブラリをインポートします

[source, python]
----
from rdkit import Chem, DataStructs
from rdkit.Chem import AllChem, Draw
import numpy as np
import pandas as pd
from ggplot import *
from sklearn.decomposition import PCA
import os
----

ダウンロードしたsdfを読み込んで、製薬企業とドキュメントIDの対応が取れるようにしてそれぞれの化合物についてフィンガープリントを構築します。もし不明な点があれば6章を確認してください。

[source, python]
----
oxrs = [("CHEMBL3098111", "Merck" ),("CHEMBL3867477", "Merck" ),
        ("CHEMBL2380240", "Rottapharm" ),("CHEMBL3352684", "Merck" ),
        ("CHEMBL3769367", "Merck" ),("CHEMBL3526050", "Actelion" ),
        ("CHEMBL3112474", "Actelion" ),("CHEMBL3739366", "Heptares" ),
        ("CHEMBL3739395", "Actelion" ), ("CHEMBL3351489", "Eisai" )]

fps = []
docs = []
companies = []

for cid, company in oxrs:
    sdf_file = os.path.join("ch08", cid + ".sdf")
    mols = Chem.SDMolSupplier(sdf_file)
    for mol in mols:
        if mol is not None:
            fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)
            arr = np.zeros((1,))
            DataStructs.ConvertToNumpyArray(fp, arr)
            docs.append(cid)
            companies.append(company)
            fps.append(arr)
fps = np.array(fps)
companies = np.array(companies)
docs = np.array(docs)
----

フィンガープリントの情報を確認すると10の論文から293化合物のデータが得られていることがわかります。

[source, python]
----
fps.shape
# (293, 2048)
----

これで主成分分析の準備完了です。主成分の数はn_componentsで指定できますが今回は二次元散布したいので2にします。

[source, python]
----
pca = PCA(n_components=2)
x = pca.fit_transform(fps)
----

描画します。colorオプションを変えると、それぞれのラベルに応じた色分けがされるので、OMPANYとDOCIDの2つの属性を選んでみました。

[source, python]
----
d = pd.DataFrame(x)
d.columns = ["PCA1", "PCA2"]
d["DOCID"] = docs
d["COMPANY"] = companies
g = ggplot(aes(x="PCA1", y="PCA2", color="COMPANY"), data=d) + geom_point() + xlab("X") + ylab("Y")
g
----

各製薬会社がどのような化合物を最適化したのかがわかるようになりました。ケミカルスペースの中心部に各社重なる領域があるので、Merck, Acterion, Eisai, Heptaressは似たような化合物を最適化していたと思われます。Acterionはうまく独自性のある方向(左下)に展開できたのか、展開できなくてレッドオーシャン気味の中心部に進出してきたのかは興味深いです。

またMerckは色々な骨格を最適化していたようです。同時に最適化したのか先行がこけてバックアップに走ったのかわかりませんが、多数の骨格の最適化が動いていたのは間違いないので、ターゲットとしての魅力が高かったということでしょう。実際link:https://www.ebi.ac.uk/chembl/beta/compound_report_card/CHEMBL1083659/[SUVOREXANT]は上市されましたしね。

image:ch08/pca01.png[PCA, size=400, pdfwidth=48%] image:ch08/pca02.png[PCA, size=400, pdfwidth=48%]

.patinformatics
****
本章では論文データを利用しましたが、実際の現場でこのような解析をする場合には論文データは使いません。なぜなら企業が論文化するときはそのプロジェクトが終わったこと（成功して臨床に進んだか、失敗して閉じたか）を意味するからです。実際の場面では特許データを利用して解析をします。

このような解析とlink:http://rkakamilan.hatenablog.com/entry/2017/12/17/235417[メディシナルケミストの経験と洞察力]をもとに他社状況を推測しながら自分たちの成功を信じてプロジェクトは進んでいきます。
****

=== tSNEをつかったマッピング

PCAよりもtSNEのほうが分離能がよく、メディシナルケミストの感覚により近いと言われています。sklearnではPCAをTSNEに変更するだけです。

[source, python]
----
from sklearn.manifold import TSNE
tsne = TSNE(n_components=2, random_state=0)
tx = tsne.fit_transform(fps)
----

描画するとわかりますが、PCAに比べてよく分離されています。

[source, python]
----
d = pd.DataFrame(tx)
d.columns = ["PCA1", "PCA2"]
d["DOCID"] = docs
d["COMPANY"] = companies 
g = ggplot(aes(x="PCA1", y="PCA2", color="COMPANY"), data=d) + geom_point() + xlab("X") + ylab("Y")
g
----

image::ch08/tsne01.png[PCA, size=500]

今回紹介したPCA,tSNEの他にも色々な描画方法があるので調べてみるとよいでしょう。

=== 化合物の距離情報に基づいたクラスタリング(HDBSCANを使ってみる)

今回取り上げた事例では、化合物のFingerprintをPCAやtSNEを用いて次元圧縮した結果に企業名を載せると綺麗にマッピングができました。
このように、予めラベル（今回は企業名）がある場合、次元圧縮後にラベルを載せて眺めることができますが、毎回情報があるとは限りません。このような場合、6章で簡単に紹介しましたが、クラスタリングを行い化合物を適当なグループに分割することがあります。

クラスタリングには様々な方法があります。例えば、ｋ近傍法や、階層別クラスタリングなどが有名です。
クラスタリングで悩ましいのは、どれくらいのサイズのクラスタに分けるべきか？だと思います。

例えば、今回の例であれば付与するクラスタラベルがほぼ企業名に対応するというように、いい感じに割り振ってくれると嬉しいわけです。
このような目的に合うアルゴリズムは色々ありますが、今回はlink:https://link.springer.com/chapter/10.1007/978-3-642-37456-2_14[HDBSCAN]を紹介します。HDBSCANは密度に基づくクラスタリング手法です。

インストールはCondaまたは、Pipコマンドでインストールできます。また以下のコードで可視化にはlink:https://seaborn.pydata.org/[seaborn]を使います。入れていない方はこれもインストールしましょう。
データの読み込みは上のパートと同じです。
コードを実行する際にWarningが出るのが嫌なのでRDLogger.DisableLog('rdApp.*')を入れて抑制しました。

[source, python]
----
pip install hdbscan
#or
conda install -c conda-forge hdbscan
conda install -c conda-forge seaborn
----

さて、インストールが終わったら早速使ってみましょう！

[source, python]
----
%matplotlib inline
import os
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from rdkit import Chem, DataStructs
from rdkit.Chem import AllChem, Draw
from rdkit import RDLogger
from sklearn.manifold import TSNE
from hdbscan import HDBSCAN
## 以下のパッケージは後半で利用します
from sklearn.model_selection import train_test_split
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.ensemble import RandomForestRegressor
from mlinsights.mlmodel import PredictableTSNE

sns.set_context('poster')
sns.set_style('white')
sns.set_color_codes()
plot_kwds = {'alpha' : 0.5, 's' : 80, 'linewidths':0}
RDLogger.DisableLog('rdApp.*')
seed = 794

oxrs = [("CHEMBL3098111", "Merck" ),  ("CHEMBL3867477", "Merck" ),  ("CHEMBL2380240", "Rottapharm" ),
             ("CHEMBL3352684", "Merck" ),  ("CHEMBL3769367", "Merck" ),  ("CHEMBL3526050", "Actelion" ),
             ("CHEMBL3112474", "Actelion" ),  ("CHEMBL3739366", "Heptares" ),  ("CHEMBL3739395", "Actelion" ), 
             ("CHEMBL3351489", "Eisai" )]
fps = []
docs = []
companies = []
mol_list = []
for cid, company in oxrs:
    sdf_file = os.path.join("ch08", cid + ".sdf")
    mols = Chem.SDMolSupplier(sdf_file)
    for mol in mols:
        if mol is not None:
            mol_list.append(mol)
            fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2)
            arr = np.zeros((1,))
            DataStructs.ConvertToNumpyArray(fp, arr)
            docs.append(cid)
            companies.append(company)
            fps.append(arr)
fps = np.array(fps)
companies = np.array(companies)
docs = np.array(docs)

trainIDX, testIDX = train_test_split(range(len(fps)), random_state=seed)
----

データの準備ができたので、まずTSNEで企業のラベルとともにケミカルスペースを眺めましょう。

[source, python]
----
tsne = TSNE(random_state=seed)
res = tsne.fit_transform(fps)
plt.clf()
plt.figure(figsize=(12, 6))
sns.scatterplot(res[:,0], res[:,1], hue=companies, **plot_kwds)
----

image::ch08/tsne02.png[TSNE2, size=500]

きれいに分かれています。では、HDBSCANの実行とその結果の可視化をしてみます。

HDBSCANのお作法はScikit-learnに準拠しているのでオブジェクトを作ってFitをコールするだけで完了です。クラスタリング実施の際に、各データの特徴量に基づく距離が必要です。HDBSCANにはデフォルトでユークリッド距離、コサイン距離など多くのメトリクスが用意されていますが、今回は化合物のFingeprintでの距離ということでタニモト係数を使います。これは自分で実装する必要があります。2つのNumpy arrayを受け取り距離を返す関数を定義して、HDBSCANに渡します。ここではtanimoto_distという関数を定義しました。このようにユーザーオリジナルの関数を実装する場合は、metric='pyfunc'として、func引数に定義した関数を渡します。

TIP: Numpyのarrayを2つ受ける関数と書きましたがもっと複雑な関数を使いたい場合はfunctools link:https://docs.python.org/3.7/library/functools.html[partical]などを使うことも可能でしょう。

[source, python]
----
def tanimoto_dist(ar1, ar2):
    a = np.dot(ar1, ar2)
    b = ar1 + ar2 - ar1*ar2
    return 1 - a/np.sum(b)

clusterer = HDBSCAN(algorithm='best', min_samples=5, metric='pyfunc', func=tanimoto_dist)
clusterer.fit(fps)
----

計算が終わると、clustererオブジェクトのlabels_というプロパティにラベル付与されています。

それを使ってプロットしてみましょう。今回はmin_sample=5とし、クラスタを形成する場合、最低限含まれるべき化合物数を5としました。このあたりのパラメータを増減すると、異なる出力が得られますので、ある程度試行錯誤してみるのも良いでしょう。

以下のプロットにおいて灰色になっている部分は、どのクラスタにも属さないと判断されたものとなります。

[source, python]
----
plt.clf()
plt.figure(figsize=(12, 6))
palette = sns.color_palette()
cluster_colors = [sns.desaturate(palette[col], sat)
                 if col >= 0 else (0.5, 0.5, 0.5) for col, sat in zip(clusterer.labels_, clusterer.probabilities_)]
plt.scatter(res[:,0], res[:,1], c=cluster_colors, **plot_kwds)
----

image::ch08/tsne03.png[TSNE3, size=500]

いかがでしょうか。おおよそですが、TSNEで分離されている島とラベルが対応しています。どちらも入力は化合物のFingerprintで似ているものを集めるという観点ですので当たり前かもしれませんが、密度に基づいて客観的にラベルを付与できる手法として、
HDBSCANは覚えておいていい手法の一つではないでしょうか。

=== 予め定義したケミカルスペースに新しいデータを足したい。

さて、ここまでで何かしらの化合物の特徴を元にそれを低次元のケミカルスペースに投影する手法を学びました。

PCAやTSNEを使ってマップしたときに、次に作る化合物はこの空間のどこに位置するのだろうか？という思うことありませんか。また、HTSライブラリの拡張など際に、今までにないケミカルスペースを埋めたい！といったときにも既存のケミカルスペースとの比較がしたいと思いませんか。

既存のケミカルスペースに新しい化合物を投影できるのでしょうか？PCAやTSNEは残念ながらできません。全化合物を入れて再計算する必要があります。自己組織化マップ(SOM)を使うという手はありますが、この章では、できないと言っておきつつ、PCAやTSNEで新しいデータをプロットする方法を紹介します。

できないといったことを実現するためには発送の転換が必要です。トレーニングデータを使い特徴量＝＞低次元空間への次元圧縮の予測モデルを作るのです。Fingerprintを入力、2次元圧縮したｘｙを予測するモデルを作ればいいですね！（もちろんこの手法は万全ではなくモデルに結果が大きく依存します）
この予測可能なTSNEを実装してるパッケージがlink:http://www.xavierdupre.fr/app/mlinsights/helpsphinx/index.html[mlinsights]です。このパッケージはpip コマンドでインストール可能です。

[source, python]
----
pip install mlinsights
----

mlinsightsは複数の手法を実装していますが今回は、PredictableTSNEのみの事例紹介に絞ります。
ランダムにトレーニングとテストデータに分割しトレーニングデータでTSNEを実施、その結果をRandomForestとGausianProcessRegressorの2つの手法で学習、このモデルを用いてテストデータを投影するというテストをします。

[source, python]
----
trainFP = [fps[i] for i in trainIDX]
train_mol = [mol_list[i] for i in trainIDX]

testFP = [fps[i] for i in testIDX]
test_mol = [mol_list[i] for i in testIDX]
allFP = trainFP + testFP
tsne_ref = TSNE(random_state=seed)
res = tsne_ref.fit_transform(allFP)
plt.clf()
plt.figure(figsize=(12, 6))
sns.scatterplot(res[:,0], res[:,1], hue=['train' for i in range(len(trainFP))] + ['test' for i in range(len(testFP))])
----

ランダムスプリットなので、まんべんなくサンプリングできています。

image::ch08/ptsne01.png[pTSNE1, size=500]

PredictableTSNEもscikit-learnと同じなので、オブジェクトを作ってFitで学習、Transformデータの次元削減をします。transformerにはTSNEやPCA次元圧縮用のオブジェクトを、Estimatorにはその結果を元にモデルを作る学習機を渡します。後でトレーニングデータとテストデータを重ねるのでkeep_tsne_outputs=Trueとしています。
注意としてfitをコールするときに本来であれば不要ですがyに対応する値を渡す必要があります。tSNE、PCAは基本Xだけで計算が完結し、ｙは不要ですが、Transformerにはそれ以外のオブジェクトも渡せるようになっているためです。TSNEでは、yはあっても無視されるので、あってもなくても計算に影響はありません。下のコードではダミーの値を渡しています（ただのIndex）

[source, python]
----
rfr = RandomForestRegressor(random_state=seed)
tsne1 = TSNE(random_state=seed)
pred_tsne_rfr = PredictableTSNE(transformer=tsne1, estimator=rfr, keep_tsne_outputs=True)
pred_tsne_rfr.fit(trainFP, list(range(len(trainFP))))

pred1 = pred_tsne_rfr.transform(testFP)
plt.clf()
plt.figure(figsize=(12, 6))
plt.scatter(pred_tsne_rfr.tsne_outputs_[:,0], pred_tsne_rfr.tsne_outputs_[:,1], c='blue', alpha=0.5)
plt.scatter(pred1[:,0], pred1[:,1], c='red', alpha=0.5)
----

image::ch08/ptsne02.png[pTSNE2, size=500]

赤いポイントがテストデータです。意外といい感じです。
次はGaussianProcessで同じことをやってみます。

[source, python]
----
gbr = GaussianProcessRegressor(random_state=seed)
tsne2 = TSNE(random_state=seed)
pred_tsne_gbr = PredictableTSNE(transformer=tsne2, estimator=gbr, keep_tsne_outputs=True)
pred_tsne_gbr.fit(trainFP, list(range(len(trainFP))))
pred2 = pred_tsne_gbr.transform(testFP)
plt.clf()
plt.figure(figsize=(12, 6))
plt.scatter(pred_tsne_gbr.tsne_outputs_[:,0], pred_tsne_gbr.tsne_outputs_[:,1], c='blue', alpha=0.5)
plt.scatter(pred2[:,0], pred2[:,1], c='red', alpha=0.5)
----

image::ch08/ptsne03.png[pTSNE3, size=500]

GPモデルはあまり性能が出ませんでした。PredictableTSNEは新しい化合物の既存スペースへの投影の一つのツールとなり得ますが、この例のようにモデルにより結果が大きく左右される懸念があるようです。
実プロジェクト投入時にはよく検証しないとメドケムの方をミスリードするリスクがあるかもしれません。一つのアプローチとして紹介させてもらいました。


TIP: 新しバージョンのpandasを利用しているとggplotを呼ぶ際にエラーが起きることがあるかもしれません。link:https://github.com/yhat/ggpy/issues/662[github_issue]　解決策はこのリンクにあるようにインストールされたggplotのフォルダ内のコードggplot/utils.pyのpd.tslib.Timestampをpd.Timestampに、ggplot/stats/smoothers.pyのfrom pandas.lib import Timestamp を from pandas import Timestampに変えると動くと思います。

<<<
